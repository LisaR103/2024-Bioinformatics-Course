{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362e4a67-2a98-4b6c-aed8-8562360ce2f1",
   "metadata": {},
   "source": [
    "# Strings\n",
    "\n",
    "## Table of content\n",
    "\n",
    "1. [Strings](#Strings)\n",
    "   1. [Table of content](#Table-of-content)\n",
    "2. [Definitions](#Definitions)\n",
    "   1. [Position Si](#Position-Si)\n",
    "      1. [repr](#repr)\n",
    "   2. [Substring Sij](#Substring-Sij)\n",
    "   3. [Length N](#Length-N)\n",
    "3. [String Methods](#String-Methods)\n",
    "   1. [split](#split)\n",
    "   2. [find](#find)\n",
    "   3. [in](#in)\n",
    "4. [The module re](#The-module-re)\n",
    "   1. [split](#split)\n",
    "   2. [wildcard in re](#wildcard-in-re)\n",
    "   3. [finditer](#finditer)\n",
    "   4. [findall](#findall)\n",
    "5. [Modifying strings](#Modifying-strings)\n",
    "   1. [upper and lower](#upper-and-lower)\n",
    "   2. [strip](#strip)\n",
    "   3. [replace](#replace)\n",
    "   4. [Concatenating strings](#Concatenating-strings)\n",
    "6. [Working with files](#Working-with-files)\n",
    "   1. [open](#open)\n",
    "   2. [write and save](#write-and-save)\n",
    "   3. [read](#read)\n",
    "   4. [parsing files](#parsing-files)\n",
    "7. [Bioinformatic file types](#Bioinformatic-file-types)\n",
    "   1. [fasta files](#fasta-files)\n",
    "   2. [fastq files](#fastq-files)\n",
    "   3. [genebank files](#genebank-files)\n",
    "   4. [clustalW files](#clustalW-files)\n",
    "   5. [pdb files](#pdb-files)\n",
    "12. [Exercises](#Exercises)\n",
    "    1. [Exercise 1 - Simple Strings](#Exercise-1---Simple-Strings)\n",
    "    2. [Exercise 2 - String methods](#Exercise-2---String-Methods)\n",
    "    3. [Exercise 3 - Working with Strings](#Exercise-3---Working-with-strings)\n",
    "    4. [Exercise 4 - A bot more about Strings](#Exercise-4---A-bit-more-about-Strings)\n",
    "    5. [Exercise 5 - Writing Files](#Exercise-5---Writing-Files)\n",
    "    6. [Exercise 6 - Reading a file](#Exercise-6---Reading-a-file)\n",
    "    7. [Exercise 7 - Small sequence comparison](#Exercise-7---Small-sequence-comparison)\n",
    "13. [Extras](#Extras)\n",
    "    1. [Accessing the letters of the alphabet](#Accessing-the-letters-of-the-alphabet)\n",
    "    2. [whitespaces with escape characters](#whitespaces-with-escape-characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897524a7-5e05-46e3-93e8-1e749219f83b",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "\n",
    "- Alphabets are the collection of symbols or letters that can make up the string\n",
    "  - Σdna = {A,G,C,T} ; for nucleotides\n",
    "  - Σamino = {A,C,D,E,F,G,H,I,K,L,M,N,P,Q,R,S,T,V,W,Y}; for amino acids\n",
    "- Each **Element E** of an alphabet is named symbol or letter\n",
    "- **String S** is a juxtaposition of symbols or letters from the alphabet Sigma\n",
    "  - S = (ΣE) (An order of symbols is defined)\n",
    "  - E.g: S = „ATGGAATGCTAATAG“\n",
    "- **Position Si** is the letter E on position i in the string (starts at position 0!)\n",
    "- **Substring Sij** are the letters from position Si to Sj excluding the latter\n",
    "- **Length N** of a string is the number of letters in it\n",
    "- **Split Spliti** is the splitting of a string in two substrings at position i. Two new strings S0i and SiN are created\n",
    "- **Split SplitDelimitor** is the splitting of a string in multiple substrings divided at the delimitor (which can be anything, but examples could be a space, a tab, a comma etc.). The number of substrings is equal to the number of occurrences of the delimitor +1\n",
    "- **Prefix n** is a substring of the string S which contains the first n letters of S\n",
    "- **Suffix n** is a substring of the string S which contains the last n letters of S\n",
    "\n",
    "## Position Si\n",
    "\n",
    "We can access individual letters/symbols of a string similar to accessing elements of a list. \n",
    "\n",
    "- Indexing starts at 0\n",
    "- Negative indices access the string from the back\n",
    "- It is only possible to access elements that exist, otherwise there is an out of range error.\n",
    "- linebreaks (`\\n`, `\\t` etc.) which need an escape character are considered *one character*\n",
    "\n",
    "```\n",
    "S = \"Examplestring\"\n",
    "S[0] = \"E\"\n",
    "S[1] = \"x\"\n",
    "S[-1] = \"g\"\n",
    "S[20] = ERROR\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94578d29-9a7c-4be7-b4bd-2ff76ef97838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "x\n",
      "g\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(S[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(S[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "S = \"Examplestring\"\n",
    "print(S[0])\n",
    "print(S[1])\n",
    "print(S[-1])\n",
    "print(S[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de632e08-3088-4c90-9614-fcf4d2fb4d83",
   "metadata": {},
   "source": [
    "### repr\n",
    "\n",
    "If we access a character that is represented by nothing (e.g. space, tab, linebreak) this shows in print like we didn't access anything. Using `repr`inside `print` allows us to see them better by adding `''`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ac9d19-3d4d-49ad-bd3c-b8dff51b6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "' '\n"
     ]
    }
   ],
   "source": [
    "S = \"Example string\"\n",
    "print(S[7])\n",
    "print(repr(S[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c0fbe23-018d-4139-893f-1958790b3cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####\n",
      "Example\n",
      "string\n",
      "####\n",
      "'Example\\nstring'\n",
      "####\n",
      "\n",
      "\n",
      "####\n",
      "'\\n'\n",
      "####\n"
     ]
    }
   ],
   "source": [
    "S = \"Example\\nstring\"\n",
    "\n",
    "print(\"####\")\n",
    "print(S)\n",
    "\n",
    "print(\"####\")\n",
    "print(repr(S))\n",
    "\n",
    "print(\"####\")\n",
    "print(S[7])\n",
    "\n",
    "print(\"####\")\n",
    "print(repr(S[7]))\n",
    "\n",
    "print(\"####\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f62c2-9da4-4732-bedc-e095794cc582",
   "metadata": {},
   "source": [
    "## Substring Sij\n",
    "\n",
    "To generate a substring the string is spliced. Follows the splicing rules of lists\n",
    "\n",
    "- start index i is included\n",
    "- end index j is excluded\n",
    "- j can be higher than the length of the string, it then just goes to the last letter/symbol\n",
    "- the first or last may be left empty if we want everything from the start/till the end\n",
    "\n",
    "```\n",
    "S = \"Examplestring\"\n",
    "S[i:j]\n",
    "\n",
    "S[2:5] = \"amp\"\n",
    "S[:5] = S[0:5] = \"Examp\"\n",
    "S[5:] = S[5:12] = \"lestring\"\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf5a11c-c202-4ebf-a350-9e3e0848d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp\n",
      "Examp\n",
      "lestring\n",
      "lestring\n"
     ]
    }
   ],
   "source": [
    "S = \"Examplestring\"\n",
    "print(S[2:5])\n",
    "print(S[:5])\n",
    "print(S[5:])\n",
    "print(S[5:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e229a597-1f64-4ab9-969a-16ceb2ad526e",
   "metadata": {},
   "source": [
    "## Length N\n",
    "\n",
    "`len(S)` counts the number of symbols in the string S\n",
    "\n",
    "- including spaces, commas, linebreaks etc.\n",
    "- `\\n` etc. count as *one character*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8ad90e-d3c3-40cd-96e9-81a8e465ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S has length 13 and S2 and S3 have length 14 and 14\n"
     ]
    }
   ],
   "source": [
    "S = \"Examplestring\"\n",
    "S2 = \"Example string\"\n",
    "S3 = \"Example\\nstring\"\n",
    "\n",
    "print(f\"S has length {len(S)} and S2 and S3 have length {len(S2)} and {len(S3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd427a-fb09-4cb7-bb98-458f3a318fbb",
   "metadata": {},
   "source": [
    "# String methods\n",
    "\n",
    "## split\n",
    "\n",
    "This splits a string at the occurence of a specific symbol/letter, which is a built in string method. \n",
    "\n",
    "- It will result in a list with the substrings\n",
    "- default is space as delimitor\n",
    "- otherwise the delimitor can be specified as an argument (can be anything even several letters)\n",
    "- the delimitor is *removed* from the list and is lost!\n",
    "- If the delimitor is not encouteres split returns the entire string in a list of ine element\n",
    "\n",
    "Syntax:\n",
    "\n",
    "```\n",
    "string.split()\n",
    "\n",
    "#to use , as delimitor:\n",
    "string.split(\",\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21635318-427c-43ad-80b3-c57fca492a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'example']\n"
     ]
    }
   ],
   "source": [
    "S = \"This is an example\"\n",
    "split_list = S.split()\n",
    "print(split_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7592f7-f46d-44dd-be2a-6aad4558233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an example', ' so we need to make a bigger sentence']\n"
     ]
    }
   ],
   "source": [
    "S = \"This is an example, so we need to make a bigger sentence\"\n",
    "split_list = S.split(\",\")\n",
    "print(split_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c14408-48cf-4699-8161-8f13235093cc",
   "metadata": {},
   "source": [
    "## find\n",
    "\n",
    "The string method `find` allows us to search for substrings.\n",
    "\n",
    "- it returns the start index of the *first* occurence of the search term\n",
    "- case sensitivity applies\n",
    "- if the search term is not present find returns -1\n",
    "\n",
    "Syntax\n",
    "\n",
    "```\n",
    "string.find(\"term\")\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f382e17-d6fe-4834-b944-9880a6baff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "S = \"This is an example\"\n",
    "idx = S.find(\"is\")\n",
    "print(idx)\n",
    "\n",
    "idx2 = S.find(\"IS\")\n",
    "print(idx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648fc9e-21cd-44ba-acac-b52613595a2a",
   "metadata": {},
   "source": [
    "## in\n",
    "\n",
    "If we just want to know if a substring is present and don't care *where* it percisely is we can use `in` \n",
    "\n",
    "- it returns `True` or `False`\n",
    "\n",
    "Examples:\n",
    "\n",
    "    print(\"term\" in string)\n",
    "    \n",
    "    if \"term\" in string:\n",
    "        do something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b07c13d5-63a0-4e1b-86bf-98f0e26f788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Yeah\n"
     ]
    }
   ],
   "source": [
    "S = \"This is an example\"\n",
    "print(\"is\" in S)\n",
    "\n",
    "if \"is\" in S:\n",
    "    print(\"Yeah\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6a2a0-3dd3-4441-bdf6-319182db5976",
   "metadata": {},
   "source": [
    "# The module re\n",
    "\n",
    "This module contains functions for regular expression operations. It is part of the standard python libraries.\n",
    "\n",
    "- contains a lot of useful methods\n",
    "- we will discuss only 3, but there are many more\n",
    "- we use the functions with the point notation\n",
    "\n",
    "import Syntax:\n",
    "\n",
    "    import re\n",
    "\n",
    "A note on escape characters in re:\n",
    "\n",
    "- general re syntax prefers double `\\\\` as escape character, instead of the normal single `\\`, to avoid any unintentional effects\n",
    "- at the moment this is a warning, in future it will be a syntax error\n",
    "- to search for the actual sequence `\\n` we can either use `\\\\\\\\n` or utilize raw `r(\\\\n)`\n",
    "- escape sequences:\n",
    "\n",
    "\n",
    "\n",
    "## split\n",
    "\n",
    "similar to the built in `split`\n",
    "\n",
    "- several delimitors allowed, separated by pipes `|`\n",
    "- two arguments\n",
    "  - the delimitor(s)\n",
    "  - the string\n",
    "- Note that the delimitor definition is space sensitive, so unless the space is to be defined as (part of) the delimitor keep the symbols and pipes together\n",
    "  - `(\" \")` = single space as delimitor\n",
    "  - `(\",|;\")` = comma or semicolon as delimitor\n",
    "  - `(\", | ;\")` = comma followed by space or space followed by semicolon as delimitor\n",
    "- Returns a list with the substrings\n",
    "  - if the string starts with a delimitor the first element of the result list is an empty string\n",
    "  - if two delimitors follow each other this is also represented by an emtpy string\n",
    "  - otherwise the delimitor is simply deleted like the behaviour of built-in `split`\n",
    "  - The reason for this:\n",
    "    - `split` opens a substring, which is closed when it comes across a delimitor.\n",
    "    - If the first symbol is a delimitor the substring is closed immediately after being opened and is emtpy.\n",
    "    - Same if two delimitor follow each other: An emtpy string is produced\n",
    "    - while built in `split` ignores these emtpy strings `re.split` will include them.\n",
    "    - to exclude the empty strings see example below\n",
    "\n",
    "Syntax:\n",
    "\n",
    "    re.split(\"delimitor1|delimitor2\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "534ef1fa-8df4-4ada-a9d5-fd9e64d52beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'This is', ' a long', ' sentence', ' with weird punctuation', '', '!']\n",
      "['This is', ' a long', ' sentence', ' with weird punctuation', '!']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "S = \",This is, a long, sentence; with weird punctuation,;!\"\n",
    "S_split0 = re.split(\",|;\",S)\n",
    "\n",
    "print(S_split0)\n",
    "\n",
    "#To exclude the emtpy string:\n",
    "S_split = [elem for elem in S_split0 if len(elem)>0]\n",
    "print(S_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355312b0-3091-4c5a-889f-85596cba734e",
   "metadata": {},
   "source": [
    "## wildcard in re\n",
    "\n",
    "`.` is a wildcard standing for exactly one character\n",
    "\n",
    "- if `.` is to be used as a delimitor it needs to be combined with an escape character\n",
    "- `\\\\.` since we are in re and they prefer double `\\\\` as escape\n",
    "\n",
    "I'm not sure but it is possible that the wildcard for 0 or mire characters is `.+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7db0357-0ea2-4f48-b668-7fde4f00540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an example of two senteces', ' So I need a second sentence', '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/pq/1h0dzqv16j58hqpqtlb29y280000gn/T/ipykernel_23337/1674944002.py:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  print(re.split(\"\\.\",S))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "S = \"This is an example of two senteces. So I need a second sentence.\"\n",
    "print(re.split(\"\\.\",S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d62bbdf-8627-402b-80cb-159aa34787f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an example of two senteces', ' So I need a second sentence', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "S = \"This is an example of two senteces. So I need a second sentence.\"\n",
    "print(re.split(\"\\\\.\",S))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca03a20-1f13-4b69-8d07-b8d7f3426fe0",
   "metadata": {},
   "source": [
    "## finditer\n",
    "\n",
    "finds the start index of *all* occurences of a search term\n",
    "\n",
    "finditer returns a generator which makes usage a bit complicated to get to the indices\n",
    "\n",
    "Syntax using a list comprehension:\n",
    "\n",
    "    idcs = [m.start() for m in re.finditer(\"a\",S3)]\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- `finditer` uses two arguments: the search term and the string. \n",
    "- It produce an iterator which contains the match objects (= the found instances)\n",
    "- by looping over this iterator we can look at the match objects\n",
    "- An easy way to get to the start indices:\n",
    "  - these match objects have a method `start` which we can call by point notation and which contains the indices\n",
    "  - by looping over the the match objects we can save the indices in a list\n",
    "  - similarly there is a method called `end` which tells us where the string ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d867829-7e90-466a-8858-bdc621fe961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 35, 55]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "S = \"This is an example, of two senteces, So I need a second, sentence.\"\n",
    "\n",
    "idcs = [m.start() for m in re.finditer(\",\",S)]\n",
    "print(idcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ddd4c3b-0849-4b0f-b539-32a851f08ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(18, 19), match=','>\n",
      "18\n",
      "19\n",
      "<re.Match object; span=(35, 36), match=','>\n",
      "35\n",
      "36\n",
      "<re.Match object; span=(55, 56), match=','>\n",
      "55\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "# accessing the match objects\n",
    "test1 = re.finditer(\",\",S)\n",
    "\n",
    "for m in test1:\n",
    "    print(m)\n",
    "    print(m.start())\n",
    "    print(m.end())\n",
    "    #print(dir(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b5b37c-09ab-4d29-b49e-26b950db5e6d",
   "metadata": {},
   "source": [
    "## findall\n",
    "\n",
    "To see how *how often* my substring occurs without caring where they occur `findall` is a good option\n",
    "\n",
    "- findall will return a list with the occurences (which all look the same)\n",
    "- the length of that list is the number of occurences\n",
    "\n",
    "Syntax:\n",
    "\n",
    "    Sf = re.findall(\"term\",string)\n",
    "    len(Sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fb92e2-99db-41da-bc32-09f719ac3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', 'l', 'l', 'l']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "S = \"Hello, This is a long example\"\n",
    "Sf = re.findall(\"l\",S)\n",
    "print(Sf)\n",
    "print(len(Sf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad877e-4a7a-45f4-bedd-851c26f04e0d",
   "metadata": {},
   "source": [
    "# Modifying strings\n",
    "\n",
    "sometimes we need to make changes to the strings, e.g. set sequence data to all uppercase or all lowercase so case sensitivity doesn't mess things up\n",
    "\n",
    "## upper and lower\n",
    "\n",
    "upper and lower are a built in string methods which turns a string into all uppercase(all lowercase\n",
    "\n",
    "- we assign a new variable\n",
    "- S in itself remains unchanged, unless I reassign it onto itself!\n",
    "- upper and lower do not work inplace\n",
    "\n",
    "```\n",
    "S = \"This is a string\"\n",
    "S_upper = S.upper()\n",
    "S_lower = S.lower()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de97f24a-1c8c-48ce-a52b-7408f238eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a string\n",
      "THIS IS A STRING\n",
      "this is a string\n"
     ]
    }
   ],
   "source": [
    "S = \"This is a string\"\n",
    "S_upper = S.upper()\n",
    "S_lower = S.lower()\n",
    "\n",
    "print(S)\n",
    "print(S_upper)\n",
    "print(S_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9592f-e487-4491-b637-0f2f55f7cdc7",
   "metadata": {},
   "source": [
    "## strip\n",
    "\n",
    "strip removes whitespaces at the beginning or end of the string\n",
    "\n",
    "- like upper and lower we need to assign a new variable\n",
    "- doesn't change the originial string, unless I reassign it into itself\n",
    "\n",
    "Syntax:\n",
    "\n",
    "```\n",
    "S = \" This is a string\"\n",
    "S1 = S.strip()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a39aab49-259e-41cd-a46b-0440d847359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' This is a string'\n",
      "'This is a string'\n"
     ]
    }
   ],
   "source": [
    "S = \" This is a string\"\n",
    "S1 = S.strip()\n",
    "print(repr(S))\n",
    "print(repr(S1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c4ebf-ac53-4d4e-bda0-fd7eca1e574e",
   "metadata": {},
   "source": [
    "## replace\n",
    "\n",
    "replace changes one substring into antother.\n",
    "\n",
    "- takes two arguments\n",
    "  - the substring I want to replace\n",
    "  - what I want to replace it with\n",
    "  - This is not sensitive to wildcards (not even the search string), so `.` works as written\n",
    "\n",
    "Syntax:\n",
    "\n",
    "```\n",
    "S = \"This is a string\"\n",
    "Sreplace = S.replace(\"This\",\"That\")\n",
    "```\n",
    "\n",
    "Example how to get rid of all spaces, linebreaks and tabstops:\n",
    "\n",
    "```\n",
    "replacements = [\" \", \"\\n\",\"\\t\"]\n",
    "for repl in replacements:\n",
    "    S2 = S2.replace(repl,\"\")\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "661388ce-420b-4445-9462-e025a5b81401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This is a string'\n",
      "'That is a string'\n"
     ]
    }
   ],
   "source": [
    "S = \"This is a string\"\n",
    "Sreplace = S.replace(\"This\",\"That\")\n",
    "print(repr(S))\n",
    "print(repr(Sreplace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3817eec-2ec2-42c2-bbbc-99941c977d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Th.is and is a string'\n",
      "'ThThat and is a string'\n"
     ]
    }
   ],
   "source": [
    "S = \"Th.is and is a string\"\n",
    "Sreplace = S.replace(\".is\",\"That\")\n",
    "print(repr(S))\n",
    "print(repr(Sreplace))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917fa576-659e-4d23-83d8-e49577ececb9",
   "metadata": {},
   "source": [
    "## Concatenating strings\n",
    "\n",
    "By using the `+` operator it is possible to simply combine two strings. They are simply added together with nothing in between\n",
    "\n",
    "```\n",
    "S1 = \"This is a string\"\n",
    "S2 = \"This is another string\"\n",
    "S3 = S1+S2\n",
    "\n",
    "S3 = \"This is a stringThis is another string\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6946638d-d1c3-4f14-814c-2bfbfb6c0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a stringThis is another string\n",
      "This is a string This is another string!\n"
     ]
    }
   ],
   "source": [
    "S1 = \"This is a string\"\n",
    "S2 = \"This is another string\"\n",
    "S3 = S1+S2\n",
    "print(S3)\n",
    "S4 = S1 + \" \" + S2 + \"!\"\n",
    "print(S4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff1c661-542e-4cfa-bead-957ad42df42d",
   "metadata": {},
   "source": [
    "# Working with files\n",
    "\n",
    "It is realatively simple to create files in Python. The first step is always opening a file\n",
    "\n",
    "## open\n",
    "\n",
    "- Takes two arguments\n",
    "  - the file name (or (relative or absolute) path to the file)\n",
    "  - what we want to do with the file\n",
    "    - \"w\": writing, creates new or overwrites existing content\n",
    "    - \"a\": appending, adds to an existing file (also works on non-exisiting files)\n",
    "    - \"r\": reading, works only for existing files\n",
    "- we always need to assign the file to a variable!!\n",
    "\n",
    "```\n",
    "file = open(\"TestFile.txt\",\"w\")\n",
    "```\n",
    "\n",
    "## write and save\n",
    "\n",
    "to write into a file we use the built in method `write` with point notation\n",
    "\n",
    "- takes a single argument, which has to be a string!\n",
    "- doesn't create linebreaks between two `write` statements, if we want them we have to add them!!\n",
    "- to add several strings in one go they may be added by `+` \n",
    "- f strings can be used as well to input variables\n",
    "- several write statments underneath each other are alled added to the file one after the other\n",
    "  - this is the part where linebreaks are not added!! its like + with strings\n",
    "- the file doesn't need to exist for \"w\", it is created in the working directory when we close it\n",
    "- the content is not saved until we close the file with `file.close()`\n",
    "\n",
    "```\n",
    "a = \"test\"\n",
    "b = 34\n",
    "# a simple write\n",
    "file.write(\"string\")\n",
    "file.write(\"string1\" + a + str(234) + str(b) + \"\\n\")\n",
    "file.close()\n",
    "```\n",
    "\n",
    "Alternatively we use the whole thing including the opening in a `with` statement. This is then saved automatically when the `with` statement is over:\n",
    "\n",
    "```\n",
    "with open(\"Filename.txt\", \"w\") as with_file:\n",
    "    with_file.write(string)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bf6d3f3-deab-4165-8680-f3e203c4d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Test.txt\",\"w\")\n",
    "file.write(\"Hello world!\\n\")\n",
    "# add a visual separator, 20 x #\n",
    "file.write(20*'#' + \"\\n\")\n",
    "file.write(\"My name is Lisa\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da9d2075-1eda-46ed-a077-9c6cd48a4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Test2.txt\", \"w\") as with_file:\n",
    "    with_file.write(\"hello garden\\n\")\n",
    "    with_file.write(50*'-' + \"\\n\")\n",
    "    with_file.write(\"My name is Lisa R\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1abcee03-95dc-43c2-8d8a-37e0155dbe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Test.txt\",\"a\")\n",
    "file.write(\"\\nSome more lines\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f066958-cb12-45e6-a3b0-c2d9e7e0e03c",
   "metadata": {},
   "source": [
    "## read\n",
    "\n",
    "It is best to always use a `with` statement to read a file to avoid leaving itopen when done\n",
    "\n",
    "```\n",
    "with open(\"Filename.txt\",\"r\" as read_file:\n",
    "```\n",
    "\n",
    "inside there are three ways of reading the file:\n",
    "\n",
    "1. reading the entire file in as one big string\n",
    "   - contains the whole test including all linebreaks, special characters etc.\n",
    "   - for small files (max 20-30 line), as otherwise the computer gets *very* slow\n",
    "2. reading the lines one by one and saving each line as element of a list (for small files)\n",
    "   - includes the linebreaks at the end of each element\n",
    "3. loop over every line individually, this has the advantage that only one line at a time is storedin the memory\n",
    "   - a useful line of code inside the loop is to remove the linebreak at the end, since then the last character is actually the last one we see in print\n",
    "\n",
    "```\n",
    "# 1. whole content in one big string\n",
    "with open(\"Filename.txt\",\"r\") as read_file:\n",
    "    content = read_file.read()\n",
    "\n",
    "# 2. each line is one element of a list\n",
    "with open(\"Filename.txt\",\"r\") as read_file2:\n",
    "    lines = read_file2.readlines()\n",
    "\n",
    "# 3. looping over the lines\n",
    "with open(\"TestFile.txt\",\"r\") as read_file3:\n",
    "    for line in read_file3:\n",
    "        line_adj = line.replace(\"\\n\",\"\")\n",
    "        print(line_adj)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8c56ec6-9e16-4f45-823c-75b4eb4a894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "####################\n",
      "My name is Lisa\n",
      "Some more lines\n",
      "\n",
      "'Hello world!\\n####################\\nMy name is Lisa\\nSome more lines\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(\"Test.txt\",\"r\") as read_file:\n",
    "    content = read_file.read()\n",
    "print(content)\n",
    "\n",
    "print(repr(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b7fba3e-edca-434d-9c7a-bcc5577652ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello world!\\n', '####################\\n', 'My name is Lisa\\n', 'Some more lines\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"Test.txt\",\"r\") as read_file:\n",
    "    lines = read_file.readlines()\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76469eb5-93fe-4b30-8450-7454322f440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello world!\\n'\n",
      "'####################\\n'\n",
      "'My name is Lisa\\n'\n",
      "'Some more lines\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(\"Test.txt\",\"r\") as read_file:\n",
    "    for line in read_file:\n",
    "        print(repr(line))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4768397-8cd9-4e6f-8897-f28058ef783e",
   "metadata": {},
   "source": [
    "## parsing files\n",
    "\n",
    "Many bioinformatics files contain information we don't need.\n",
    "\n",
    "Picking the informatino we do need is called parsing. \n",
    "\n",
    "To be able to do this we need to know what the file looks like, to do this we follow 4 steps:\n",
    "\n",
    "1. Read in the file\n",
    "2. Iterate over the file line by line\n",
    "3. Diassemble the lines so only necessary informatino is retained -> Know the format!\n",
    "4. Save the data in a Python-usable datastructure\n",
    "\n",
    "Before you start writing a parser ask yourself the following questions:\n",
    "\n",
    "1. Can I use an already existing parser?\n",
    "2. Do I need to make the parser by myself?\n",
    "   1. Which information do I need?\n",
    "   2. How do I have to dismantle each line?\n",
    "   3. Which substrings can be used as marker for my data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb775698-1f14-44e6-b3f8-c031302b3b27",
   "metadata": {},
   "source": [
    "# Bioinformatic file types\n",
    "\n",
    "Most Bioinformatic files are simple text files with a specific extension. Some of the most common are:\n",
    "\n",
    "- fasta\n",
    "- fastq\n",
    "- genbank (gb)\n",
    "- clustal\n",
    "- pdb\n",
    "- xml\n",
    "- json\n",
    "- mmCIF\n",
    "- and many more\n",
    "\n",
    "## fasta files\n",
    "\n",
    "Fasta files are used to save and relay raw sequences with only very little additinoal data\n",
    "\n",
    "Extensions (do not influence the content, simply help us identify the sequence type):\n",
    "\n",
    "- .fasta (general sequences)\n",
    "- .faa (protein sequences)\n",
    "- .fna (nucleic acid sequences)\n",
    "\n",
    "Makeup is always one (single!) line starting with `>` which contains the name (and sometimes additional information) of the sequence followed by one or more lines containing the corresponding sequence itself\n",
    "\n",
    "A file can contain several sequences underneath each other separated by their respective name lines\n",
    "\n",
    "There are two good parsers for fasta files that can all easily import the sequence and have each a few other extras:\n",
    "\n",
    "**SeqIO from Biopython**\n",
    "\n",
    "- using `parse()` (not `read()`!!)\n",
    "- generates a FastaIterator object containing one sequence object for each sequence\n",
    "- we iterate over the sequence objects with a loop\n",
    "- also used for many other filetypes\n",
    "- https://biopython.org/wiki/SeqIO\n",
    "\n",
    "Syntax:\n",
    "\n",
    "```\n",
    "from Bio import SeqIO\n",
    "\n",
    "fasta1 = SeqIO.parse(\"Filename.fasta\",\"fasta\")\n",
    "\n",
    "for record in fasta1:\n",
    "    print(record.seq) # for the sequence\n",
    "    print(record.id) # for the sequence name\n",
    "```\n",
    "\n",
    "**fastaparser**\n",
    "\n",
    "- needs to be installed (not part of main Python)\n",
    "- file is opened with a `with` statement\n",
    "- we need to loop over the resulting object to access the sequences\n",
    "- there is a standard and a quick method of reading in the data\n",
    "  - the standard results in a object where we can access the sequence with the method `seq.sequence_as_string()`\n",
    "  - the quick method results in an object that has the sequence as an attribute `seq.sequence` (without `()`)\n",
    "  - the standard method has many more options that can be used, e.g. to update the id line, to calculate gc_content etc. etc. see below \n",
    "\n",
    "\n",
    "```\n",
    "import fastaparser\n",
    "\n",
    "with open(\"Filename.fasta\",\"r\") as fasta_file:\n",
    "    fasta1 = fastaparser.Reader(fasta_file)\n",
    "    for seq in fasta1:\n",
    "        print(seq.sequence_as_string())\n",
    "\n",
    "# OR\n",
    "\n",
    "with open(\"Filename.fasta\",\"r\") as fasta_file:\n",
    "    fasta1 = fastaparser.Reader(fasta_file, parse_method = \"quick\")\n",
    "    for seq in fasta1:\n",
    "        print(seq.sequence)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36313231-50d1-48d6-a931-4b2a18d50ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr|B3JI28|B3JI28_9BACT\n",
      "\n",
      "MELKTQEVMKKLISKLYTAWLIITVGLFSACTPDSFELEGKDVTVDDLVEGIAFSITHDSENPNIVYLKSLMPSSYQVCWQHPQGRSQEREVTLQMPFEGKYEVTFGVQTRGGIVYGNPATFTIDSFCADFVNDDLWTYLTGGVNNEKVWIFDNGSYGYAAGEMTYADPSTTVEWNNWSANWDPGVGHTGDDAIWESTMTFGLKGGANVTVYNSSSKETASGTFMLNTSNHTITFTDCELLHTPSWSDRSTNWSRDLKLLELDENHMRIGVMRDNSEGPWWLIWNFVSKEYADNYVPEDKPDPEPALPDGWEDMVSEVVTSKIKWTMSADVPFDWANLDGSLMNNFTAGNYPDWATPVSGLDQLSMTLDSKTMTYEFAMPDGTTASGTYTLDEKGIYTFSGNVPSYHIGGGDIMFGADGNNQLRILSIESAAGNVMGMWVGARSAEKDEYQAYHFIPNAGGGTSQPEATSIAVDNSKLVWGHLETDKNNFRIELYNMYGETASASPIDPASIVFDYSMELTFTISGLTGDAATKEYNAGLMCTADGWWPAYSGTSDVKVKGDGTYTIKMKPEAAYNGVIVFVIDIFDMFSDIADLDAVNVTIDSLKIL\n",
      "\n",
      "['_AnnotationsDict', '_AnnotationsDictValue', '__add__', '__annotations__', '__bool__', '__bytes__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__radd__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_per_letter_annotations', '_seq', '_set_per_letter_annotations', '_set_seq', 'annotations', 'count', 'dbxrefs', 'description', 'features', 'format', 'id', 'islower', 'isupper', 'letter_annotations', 'lower', 'name', 'reverse_complement', 'seq', 'translate', 'upper']\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "fasta1 = SeqIO.parse(\"B3JI28.fasta\",\"fasta\")\n",
    "for record in fasta1:\n",
    "    print(record.id) # for the sequence name\n",
    "    print()\n",
    "    print(record.seq) # for the sequence\n",
    "    print()\n",
    "    print(dir(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48045c17-dd19-4f8a-a753-d22949d812fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MELKTQEVMKKLISKLYTAWLIITVGLFSACTPDSFELEGKDVTVDDLVEGIAFSITHDSENPNIVYLKSLMPSSYQVCWQHPQGRSQEREVTLQMPFEGKYEVTFGVQTRGGIVYGNPATFTIDSFCADFVNDDLWTYLTGGVNNEKVWIFDNGSYGYAAGEMTYADPSTTVEWNNWSANWDPGVGHTGDDAIWESTMTFGLKGGANVTVYNSSSKETASGTFMLNTSNHTITFTDCELLHTPSWSDRSTNWSRDLKLLELDENHMRIGVMRDNSEGPWWLIWNFVSKEYADNYVPEDKPDPEPALPDGWEDMVSEVVTSKIKWTMSADVPFDWANLDGSLMNNFTAGNYPDWATPVSGLDQLSMTLDSKTMTYEFAMPDGTTASGTYTLDEKGIYTFSGNVPSYHIGGGDIMFGADGNNQLRILSIESAAGNVMGMWVGARSAEKDEYQAYHFIPNAGGGTSQPEATSIAVDNSKLVWGHLETDKNNFRIELYNMYGETASASPIDPASIVFDYSMELTFTISGLTGDAATKEYNAGLMCTADGWWPAYSGTSDVKVKGDGTYTIKMKPEAAYNGVIVFVIDIFDMFSDIADLDAVNVTIDSLKIL\n",
      "\n",
      "tr|B3JI28|B3JI28_9BACT\n",
      "\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_at', '_build_letter_code_sequence_and_counts', '_counts', '_current_iterator', '_description', '_gc', '_id', '_infer_sequence_type', '_inferred_type', '_sequence', '_sequence_type', '_update_description', '_update_id', '_update_sequence_type', 'at_gc_ratio', 'complement', 'count_letter_codes', 'count_letter_codes_degenerate', 'description', 'formatted_definition_line', 'formatted_fasta', 'formatted_sequence', 'from_fastasequence', 'gc_content', 'id', 'inferred_type', 'reverse', 'sequence', 'sequence_as_string', 'sequence_type']\n"
     ]
    }
   ],
   "source": [
    "import fastaparser\n",
    "\n",
    "with open(\"B3JI28.fasta\",\"r\") as fasta_file:\n",
    "    fasta1 = fastaparser.Reader(fasta_file)\n",
    "    for seq in fasta1:\n",
    "        print(seq.sequence_as_string())\n",
    "        print()\n",
    "        print(seq.id)\n",
    "        print()\n",
    "        print(dir(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "667490d4-fa91-487b-9a91-886c3da9330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MELKTQEVMKKLISKLYTAWLIITVGLFSACTPDSFELEGKDVTVDDLVEGIAFSITHDSENPNIVYLKSLMPSSYQVCWQHPQGRSQEREVTLQMPFEGKYEVTFGVQTRGGIVYGNPATFTIDSFCADFVNDDLWTYLTGGVNNEKVWIFDNGSYGYAAGEMTYADPSTTVEWNNWSANWDPGVGHTGDDAIWESTMTFGLKGGANVTVYNSSSKETASGTFMLNTSNHTITFTDCELLHTPSWSDRSTNWSRDLKLLELDENHMRIGVMRDNSEGPWWLIWNFVSKEYADNYVPEDKPDPEPALPDGWEDMVSEVVTSKIKWTMSADVPFDWANLDGSLMNNFTAGNYPDWATPVSGLDQLSMTLDSKTMTYEFAMPDGTTASGTYTLDEKGIYTFSGNVPSYHIGGGDIMFGADGNNQLRILSIESAAGNVMGMWVGARSAEKDEYQAYHFIPNAGGGTSQPEATSIAVDNSKLVWGHLETDKNNFRIELYNMYGETASASPIDPASIVFDYSMELTFTISGLTGDAATKEYNAGLMCTADGWWPAYSGTSDVKVKGDGTYTIKMKPEAAYNGVIVFVIDIFDMFSDIADLDAVNVTIDSLKIL\n",
      "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '_asdict', '_field_defaults', '_fields', '_make', '_replace', 'count', 'header', 'index', 'sequence']\n"
     ]
    }
   ],
   "source": [
    "with open(\"B3JI28.fasta\",\"r\") as fasta_file:\n",
    "    fasta1 = fastaparser.Reader(fasta_file, parse_method = \"quick\")\n",
    "    for seq in fasta1:\n",
    "        print(seq.sequence)\n",
    "        print(dir(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b470bd59-6ebc-420e-b52b-506c12e559c4",
   "metadata": {},
   "source": [
    "## fastq files\n",
    "\n",
    "Also used for storing biological seqeunces, most often nucleotide *and its corresponding quality score*\n",
    "\n",
    "- Sequence and quality score are encoded in single character\n",
    "- standard outpu for high throughput sequencing, e.g Illumina\n",
    "- makeup: blocks of 4 line-separated fields\n",
    "   1. begins with `@` and is followed by the indetifiers and optionally a description (e.g. length)\n",
    "   2. raw sequence letters\n",
    "   3. begins with a `+` and is optionally followed by the identifier and/or description again\n",
    "   4. encodes the quality values for fiels 2\n",
    "- quality values are from lowest to highest:\n",
    "   - !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n",
    "   - this includes the markers for fields 1 and 3, so multiple line sequences are really difficult to parse\n",
    "   - that's why these days we have single line reads only\n",
    "   - also these days mostly the snippets are shorter (~100 bp in short-read Illumina sequencing)\n",
    " \n",
    "fastq files can be read in like fasta files using the SeqIO parser.\n",
    "\n",
    "## genebank files\n",
    "\n",
    "these are files developed and used by the NCBI for the databases Nucleotide or Gene\n",
    "\n",
    "- extenstion .gp\n",
    "- contain more infrormation than fasta files\n",
    "   - about the sequence\n",
    "   - references\n",
    "   - Features (in depth info, e.g. coding region etc.)\n",
    "      - only mandatory part of FEATURES is source\n",
    "      - 1..45 is a span from the first to the 45th entry of the sequence\n",
    "      - the translation in CDS is often not quite correct or even complete nonsense\n",
    "   - at the end of the file in ORIGIN there is the seqeunce\n",
    "   - see the powerpoint for more details\n",
    "\n",
    "Can be read in with SeqIO, which results in a obejct with a lot of useful attributes\n",
    "\n",
    "- id: single string\n",
    "- description: single string\n",
    "- sequence: single string\n",
    "- features: list of several SeqFeature objects, one for each entry in the features table of the corresponding sequence\n",
    "\n",
    "```\n",
    "from Bio import SeqIO\n",
    "\n",
    "genbank1 = SeqIO.parse(\"Filename.gb\", \"genbank\")\n",
    "for record in genbank1:\n",
    "    print(record.id)\n",
    "    print(record.description)\n",
    "    print(record.seq)\n",
    "    print(record.features)\n",
    "```\n",
    "\n",
    "## clustalW files\n",
    "\n",
    "This is used to store several sequences that are aligned (pairwise alignment, e.g. Needleman-Wunsch). Many if not all multiple sequence alignment tools support the clustalW format for their outputs. To look at alignments rather use Jalview\n",
    "\n",
    "- They often have the extension .aln but .clustal is also possible\n",
    "- These files contain the result of a multiple sequence Alignment and follow very specific rules\n",
    "- Each file must start with the words \"CLUSTAL\" or \"CLUSTALW“ and other information in the first line is ignored\n",
    "- This is followed by one or more empty lines\n",
    "- then comes one or more blocks of data\n",
    "  - Each block consists of multiple lines with one line representing one sequence of your multiple sequence alignment\n",
    "  - Each line consists of:\n",
    "     - the sequence name\n",
    "     - white space\n",
    "     - up to 60 sequence symbols (sequence or `-` if a particular sequence has no match at this position)\n",
    "     - optional - white space followed by a cumulative count of residues for the sequences\n",
    "  - the sequences are followed by one line showing the degree of conservation for the columns of the alignment in this block\n",
    "     - degrees of conservation are shown by:\n",
    "     - `*`: all residues or nucleotides in that column are identical\n",
    "     - `:`: conserved substitutions have been observed (score greater than .5 on the PAM 250 matrix)\n",
    "     - `.`: semi-conserved substitutions have been observed (score less than or equal to .5 on the PAM 250 matrix)\n",
    "     - ` `: no match\n",
    "  - following that come one or more empty lines before the next block of data / the end of the file\n",
    "\n",
    "Reading them in (also later this week)\n",
    "\n",
    "- SeqIO\n",
    "- AlignIO submodule of Biophyton (`alignment = AlignIO.read(\"Filename.clustal\",\"clustal\")`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203644c-1104-4ee4-9c39-e82b60e3b759",
   "metadata": {},
   "source": [
    "## pdb files\n",
    "\n",
    "pdb files are used to store 3D structure data of proteins in form of atom coordinates\n",
    "\n",
    "- two file formats\n",
    "  - pdb (extenstion .pdb) or mmCIF\n",
    "- very strict rules how the files look like\n",
    "  -  Each line contains a maximum of 80 columns, that means 80 characters\n",
    "  -  Each line represents one record and has to be self-identifying\n",
    "  - The first six columns of a line contain the record name, which must be one of the predefined record names of the pdb format\n",
    "  - The record name is then followed by a space and the remaining information / data that belongs to this record\n",
    "  - for each type of record there is a defined position for each information therein. It depends on the position in the line, not just whether there is a space between\n",
    "  \n",
    "pdb files contain multiple sections:\n",
    "1. Title section\n",
    "   - contains up to 16 different record types\n",
    "   - HEADER, which contains a classification of the molecule(s), the deposition date and the PDB identifier\n",
    "   - TITLE, contains the title for the experiment or analysis\n",
    "   - COMPND, describes the macromolecular contents of the file\n",
    "   - SOURCE, specifies the biological and/or chemical source of each biological molecule in the file\n",
    "   - AUTHOR, contains the names of the people responsible for the contents of the file\n",
    "   - JRNL, contains the primary literature citation that describes the experiment\n",
    "   - REMARK, presents experimental details, annotations, comments and information not included in other records\n",
    "      - The REMARK section is further devided into many subsections, each marked by a specific number\n",
    "      - **REMARK 465** lists missing residues, refering to either amino acids or bases in our macromolecules, that are present in the sequence which is given in the same file but are completely absent from the coordinate section. The main part of this section is a table containing:\n",
    "      - the residue name (RES), e.g. SER \n",
    "      - the chain identifier (C), e.g. A, that denotes one of the macromolecules present in the file (e.g. there can be several protein chains present and each are given an identifier, the chain identifier)\n",
    "      - sequence number (SSSEQI), e.g. 11, the position of the residue in the sequence\n",
    "      - **REMARK 470** contains information about the non-hydrogen atoms of standard residues which are missing from the coordinates. The main part is again a table containing:\n",
    "      - the residue name (RES)\n",
    "      - the chain identifier (C)\n",
    "      - the sequence number (SEQI)\n",
    "      - the names of the missing atoms (ATOMS) The atoms are called by their position. the first Carbon is carbin alpha (CA), the fourth sulfur is sulfur delta (SD) etc.\n",
    "2. Primary structure section\n",
    "   - SEQRES record, is reserved for the sequence(s) of the macromolecule(s) present in the file. This is the \"theoretical\" record against which the structure data is compared\n",
    "   - Each record contains:\n",
    "   - the serial number \n",
    "   - the chain identifier\n",
    "   - the number of residues in the chain\n",
    "   - the residue names (in triplet code for aa) of up to 13 consecutive residues\n",
    "3. Heterogen section\n",
    "   - complete description of non-standard residues in the file (ligands, co-factors like metal ions, inhibitors etc.)\n",
    "   - information about modified amino acids, e.g. glycosylated amino acids\n",
    "4. Secondary structure section\n",
    "   - helices and sheets found in protein and polypeptide structures\n",
    "5. Connectivity Annotation section\n",
    "   - existence and location of disulfide bonds and other linkages\n",
    "6. Miscellaneous Features section\n",
    "    - properties in the molecule such as environments surrounding a non-standard residue or the assembly of an active site\n",
    "7. Crystallographic and Coordinate Transformation section\n",
    "    - geometry of the crystallographic experiment\n",
    "8. *Coordinate section*\n",
    "   - exact three-dimensional coordinates of all atoms present in the structure\n",
    "   - built in a tabular way to contain all necessary information for each atom\n",
    "   - remember that the columns depend on the text column, ie.e their position in line and not spaces etc.!!\n",
    "   - 6 records ins this section: MODEL, ATOM, ANISOU, TER, HETATM and ENDMDL\n",
    "   - ATOM: Name, Atom Number, Atom name, residue name, chain identifier, residue number, x- coordinate, y-coordinate, z-coordinare, sth, sth, element symbol\n",
    "   - HETATM follows the same rules as ATOM but contain anything that is not a standard amino acid/nucleotide\n",
    "   - TER record indicates the end of one macromolecule: atom number, residue nane, chain identifier, residue number\n",
    "9. Connectivity section\n",
    "   - information about different kind of bonds (e.g Disulfide bonds, bonds inside ligands)\n",
    "   - only notes bonds not specified in the standard residue connectivity table\n",
    "10. Bookkeeping section\n",
    "    - final information about the file\n",
    "    - MASTER record, which lists the number of lines in the coordinate entry or file for selected record types\n",
    "    - END record which marks the end of the PDB file\n",
    "   \n",
    "Importing pdb files\n",
    "\n",
    "**Biopandas**\n",
    "\n",
    "```\n",
    "from biopandas.pdb import PandasPdb\n",
    "ppdb = PandasPdb()\n",
    "Struc = ppdb.read_pdb(\"filename.pdb\")\n",
    "print(Struc)\n",
    "print(Struc.df[\"ATOM\"])\n",
    "```\n",
    "\n",
    "**PDBParser**\n",
    "\n",
    "```\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "parser = PDBParser()\n",
    "structure = parser.get_structure('1kim', '1kim.pdb')\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10bf5fd-488f-430b-94cd-5d7ff2715bd5",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4584137-516e-4679-aeb2-f5c112e12c2e",
   "metadata": {},
   "source": [
    "## Exercise 1 - Simple Strings\n",
    "\n",
    "- Write a Python script that defines five string variables containing these Strings:\n",
    "  - “AAAAAAAAAAAAAAAAA”\n",
    "  - “ACTGACTGACTGACTGACTG”\n",
    "  - “HAIMGVVFTWIMALACAAPPLVGWSRY”\n",
    "  - “SSSIYNPVIYIMLNKQFRNCMLTTLCCGKNPLG”\n",
    "  - “PFSNVTGVVRSPFEQPQYYLAEPWQFSMLAAYMFLLIVLGFPINFLTLYVTVQH”\n",
    "- Print out the length of all five variables.\n",
    "- Print out the letters at the indices 0,5,10,15,20 and 25 of the five strings if possible\n",
    "- Create the substrings S-5-20, S-20-30, S-2-10 of all five strings if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "583e9d02-60cc-4c2e-aca3-1a36d4196da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String 1 has length 17\n",
      "String 2 has length 20\n",
      "String 3 has length 27\n",
      "String 4 has length 33\n",
      "String 5 has length 54\n"
     ]
    }
   ],
   "source": [
    "#create the strings\n",
    "S1 = \"AAAAAAAAAAAAAAAAA\"\n",
    "S2 = \"ACTGACTGACTGACTGACTG\"\n",
    "S3 = \"HAIMGVVFTWIMALACAAPPLVGWSRY\"\n",
    "S4 = \"SSSIYNPVIYIMLNKQFRNCMLTTLCCGKNPLG\"\n",
    "S5 = \"PFSNVTGVVRSPFEQPQYYLAEPWQFSMLAAYMFLLIVLGFPINFLTLYVTVQH\"\n",
    "\n",
    "#print the lengths\n",
    "print(f\"String 1 has length {len(S1)}\")\n",
    "print(f\"String 2 has length {len(S2)}\")\n",
    "print(f\"String 3 has length {len(S3)}\")\n",
    "print(f\"String 4 has length {len(S4)}\")\n",
    "print(f\"String 5 has length {len(S5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96a034b6-07e9-47ad-9595-187cfee218a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "\n",
      "A\n",
      "C\n",
      "T\n",
      "G\n",
      "\n",
      "H\n",
      "V\n",
      "I\n",
      "C\n",
      "L\n",
      "R\n",
      "\n",
      "S\n",
      "N\n",
      "I\n",
      "Q\n",
      "M\n",
      "C\n",
      "\n",
      "P\n",
      "T\n",
      "S\n",
      "P\n",
      "A\n",
      "F\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I make two lists of indices, since String 1 and 2 won't have indices 20 and 25\n",
    "idc1 = [0,5,10,15]\n",
    "idc2 = [0,5,10,15,20,25]\n",
    "\n",
    "#Loop over printing the indices using idc1 for S1 and S2 and idc2 for S3-5\n",
    "for idx in idc1:\n",
    "    print(S1[idx])\n",
    "print()\n",
    "\n",
    "for idx in idc1:\n",
    "    print(S2[idx])\n",
    "print()\n",
    "\n",
    "for idx in idc2:\n",
    "    print(S3[idx])\n",
    "print()\n",
    "\n",
    "for idx in idc2:\n",
    "    print(S4[idx])\n",
    "print()\n",
    "\n",
    "for idx in idc2:\n",
    "    print(S5[idx])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "998c6eb7-0be9-4dfa-8964-a0242353cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAA\n",
      "AAAAAAAA\n",
      "\n",
      "CTGACTGACTGACTG\n",
      "TGACTGAC\n",
      "\n",
      "VVFTWIMALACAAPP\n",
      "LVGWSRY\n",
      "IMGVVFTW\n",
      "\n",
      "NPVIYIMLNKQFRNC\n",
      "MLTTLCCGKN\n",
      "SIYNPVIY\n",
      "\n",
      "TGVVRSPFEQPQYYL\n",
      "AEPWQFSMLA\n",
      "SNVTGVVR\n"
     ]
    }
   ],
   "source": [
    "#Create the substrings S-5-20, S-20-30, S-2-10 of all five strings if possible (20:30 is not possible for S1 and S2)\n",
    "\n",
    "S1sub5_20 = S1[5:20]\n",
    "S1sub2_10 = S1[2:10]\n",
    "\n",
    "S2sub5_20 = S2[5:20]\n",
    "S2sub2_10 = S2[2:10]\n",
    "\n",
    "S3sub5_20 = S3[5:20]\n",
    "S3sub20_30 = S3[20:30]\n",
    "S3sub2_10 = S3[2:10]\n",
    "\n",
    "S4sub5_20 = S4[5:20]\n",
    "S4sub20_30 = S4[20:30]\n",
    "S4sub2_10 = S4[2:10]\n",
    "\n",
    "S5sub5_20 = S5[5:20]\n",
    "S5sub20_30 = S5[20:30]\n",
    "S5sub2_10 = S5[2:10]\n",
    "\n",
    "#print\n",
    "\n",
    "print(S1sub5_20)\n",
    "print(S1sub2_10)\n",
    "print()\n",
    "print(S2sub5_20)\n",
    "print(S2sub2_10)\n",
    "print()\n",
    "print(S3sub5_20)\n",
    "print(S3sub20_30)\n",
    "print(S3sub2_10)\n",
    "print()\n",
    "print(S4sub5_20)\n",
    "print(S4sub20_30)\n",
    "print(S4sub2_10)\n",
    "print()\n",
    "print(S5sub5_20)\n",
    "print(S5sub20_30)\n",
    "print(S5sub2_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d4bb4-288b-44f2-b96f-95b3963833e2",
   "metadata": {},
   "source": [
    "## Exercise 2 - String Methods\n",
    "\n",
    "Use the strings from Exercise 01 to fulfill the following tasks:\n",
    "\n",
    "- At which index are the first occurrences of the letters A, C, G, N, T and U\n",
    "- Split the strings at each appearance of the patterns “TG”, “TT” and “AA”\n",
    "- Use if statements to test whether the strings contain the patterns “FLL” and “MLT”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f2e3f26-6dd0-4b88-9d87-6ec5da45809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the strings\n",
    "S1 = \"AAAAAAAAAAAAAAAAA\"\n",
    "S2 = \"ACTGACTGACTGACTGACTG\"\n",
    "S3 = \"HAIMGVVFTWIMALACAAPPLVGWSRY\"\n",
    "S4 = \"SSSIYNPVIYIMLNKQFRNCMLTTLCCGKNPLG\"\n",
    "S5 = \"PFSNVTGVVRSPFEQPQYYLAEPWQFSMLAAYMFLLIVLGFPINFLTLYVTVQH\"\n",
    "\n",
    "# I put them in a dictionary to make looping over them easier:\n",
    "stringdict = {}\n",
    "stringdict[\"S1\"] = S1\n",
    "stringdict[\"S2\"] = S2\n",
    "stringdict[\"S3\"] = S3\n",
    "stringdict[\"S4\"] = S4\n",
    "stringdict[\"S5\"] = S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1379777-9ea2-42b3-ae60-79abba0033ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First occurence of A in S1 is at index 0\n",
      "First occurence of A in S2 is at index 0\n",
      "First occurence of A in S3 is at index 1\n",
      "First occurence of A in S4 is at index -1\n",
      "First occurence of A in S5 is at index 20\n",
      "\n",
      "First occurence of C in S1 is at index -1\n",
      "First occurence of C in S2 is at index 1\n",
      "First occurence of C in S3 is at index 15\n",
      "First occurence of C in S4 is at index 19\n",
      "First occurence of C in S5 is at index -1\n",
      "\n",
      "First occurence of G in S1 is at index -1\n",
      "First occurence of G in S2 is at index 3\n",
      "First occurence of G in S3 is at index 4\n",
      "First occurence of G in S4 is at index 27\n",
      "First occurence of G in S5 is at index 6\n",
      "\n",
      "First occurence of N in S1 is at index -1\n",
      "First occurence of N in S2 is at index -1\n",
      "First occurence of N in S3 is at index -1\n",
      "First occurence of N in S4 is at index 5\n",
      "First occurence of N in S5 is at index 3\n",
      "\n",
      "First occurence of T in S1 is at index -1\n",
      "First occurence of T in S2 is at index 2\n",
      "First occurence of T in S3 is at index 8\n",
      "First occurence of T in S4 is at index 22\n",
      "First occurence of T in S5 is at index 5\n",
      "\n",
      "First occurence of U in S1 is at index -1\n",
      "First occurence of U in S2 is at index -1\n",
      "First occurence of U in S3 is at index -1\n",
      "First occurence of U in S4 is at index -1\n",
      "First occurence of U in S5 is at index -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Where do the letters of list1 first occur in the strings?\n",
    "# This is the \"long\" loop\n",
    "\n",
    "list1 = [\"A\",\"C\",\"G\",\"N\",\"T\",\"U\"]\n",
    "\n",
    "for elem in list1:\n",
    "    print(f\"First occurence of {elem} in S1 is at index {S1.find(elem)}\")\n",
    "    print(f\"First occurence of {elem} in S2 is at index {S2.find(elem)}\")\n",
    "    print(f\"First occurence of {elem} in S3 is at index {S3.find(elem)}\")\n",
    "    print(f\"First occurence of {elem} in S4 is at index {S4.find(elem)}\")\n",
    "    print(f\"First occurence of {elem} in S5 is at index {S5.find(elem)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a872b37d-34ed-43cb-b446-cbb58a6741bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First occurence of A in S1 is at index 0\n",
      "First occurence of A in S2 is at index 0\n",
      "First occurence of A in S3 is at index 1\n",
      "First occurence of A in S4 is at index -1\n",
      "First occurence of A in S5 is at index 20\n",
      "\n",
      "First occurence of C in S1 is at index -1\n",
      "First occurence of C in S2 is at index 1\n",
      "First occurence of C in S3 is at index 15\n",
      "First occurence of C in S4 is at index 19\n",
      "First occurence of C in S5 is at index -1\n",
      "\n",
      "First occurence of G in S1 is at index -1\n",
      "First occurence of G in S2 is at index 3\n",
      "First occurence of G in S3 is at index 4\n",
      "First occurence of G in S4 is at index 27\n",
      "First occurence of G in S5 is at index 6\n",
      "\n",
      "First occurence of N in S1 is at index -1\n",
      "First occurence of N in S2 is at index -1\n",
      "First occurence of N in S3 is at index -1\n",
      "First occurence of N in S4 is at index 5\n",
      "First occurence of N in S5 is at index 3\n",
      "\n",
      "First occurence of T in S1 is at index -1\n",
      "First occurence of T in S2 is at index 2\n",
      "First occurence of T in S3 is at index 8\n",
      "First occurence of T in S4 is at index 22\n",
      "First occurence of T in S5 is at index 5\n",
      "\n",
      "First occurence of U in S1 is at index -1\n",
      "First occurence of U in S2 is at index -1\n",
      "First occurence of U in S3 is at index -1\n",
      "First occurence of U in S4 is at index -1\n",
      "First occurence of U in S5 is at index -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Where do the letters of list1 first occur in the strings?\n",
    "#This is the short dictionary loop\n",
    "\n",
    "list1 = [\"A\",\"C\",\"G\",\"N\",\"T\",\"U\"]\n",
    "\n",
    "for elem in list1:\n",
    "    for key, value in stringdict.items():\n",
    "        print(f\"First occurence of {elem} in {key} is at index {value.find(elem)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66e1a8b4-cbc0-4f4e-8b63-2a6c965a29ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TG\n",
      "S1: ['AAAAAAAAAAAAAAAAA']\n",
      "S2: ['AC', 'AC', 'AC', 'AC', 'AC', '']\n",
      "S3: ['HAIMGVVFTWIMALACAAPPLVGWSRY']\n",
      "S4: ['SSSIYNPVIYIMLNKQFRNCMLTTLCCGKNPLG']\n",
      "S5: ['PFSNV', 'VVRSPFEQPQYYLAEPWQFSMLAAYMFLLIVLGFPINFLTLYVTVQH']\n",
      "\n",
      "TT\n",
      "S1: ['AAAAAAAAAAAAAAAAA']\n",
      "S2: ['ACTGACTGACTGACTGACTG']\n",
      "S3: ['HAIMGVVFTWIMALACAAPPLVGWSRY']\n",
      "S4: ['SSSIYNPVIYIMLNKQFRNCML', 'LCCGKNPLG']\n",
      "S5: ['PFSNVTGVVRSPFEQPQYYLAEPWQFSMLAAYMFLLIVLGFPINFLTLYVTVQH']\n",
      "\n",
      "AA\n",
      "S1: ['', '', '', '', '', '', '', '', 'A']\n",
      "S2: ['ACTGACTGACTGACTGACTG']\n",
      "S3: ['HAIMGVVFTWIMALAC', 'PPLVGWSRY']\n",
      "S4: ['SSSIYNPVIYIMLNKQFRNCMLTTLCCGKNPLG']\n",
      "S5: ['PFSNVTGVVRSPFEQPQYYLAEPWQFSML', 'YMFLLIVLGFPINFLTLYVTVQH']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#“TG”, “TT” and “AA”\n",
    "list2 = [\"TG\",\"TT\",\"AA\"]\n",
    "\n",
    "for elem in list2:\n",
    "    print(elem)\n",
    "    for key, value in stringdict.items():\n",
    "        print(f\"{key}: {value.split(elem)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74fd4fa3-7dfc-47e4-9c04-085f563ffd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLL is not present in S1\n",
      "MLT is not present in S1\n",
      "FLL is not present in S2\n",
      "MLT is not present in S2\n",
      "FLL is not present in S3\n",
      "MLT is not present in S3\n",
      "FLL is not present in S4\n",
      "MLT is present in S4\n",
      "FLL is present in S5\n",
      "MLT is not present in S5\n"
     ]
    }
   ],
   "source": [
    "#Use if statements to test whether the strings contain the patterns “FLL” and “MLT”\n",
    "for key, value in stringdict.items():\n",
    "    if \"FLL\" in value: print(f\"FLL is present in {key}\")\n",
    "    else:  print(f\"FLL is not present in {key}\")\n",
    "    if \"MLT\" in value:  print(f\"MLT is present in {key}\")\n",
    "    else: print(f\"MLT is not present in {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c65ec-dfc3-43eb-819b-8086a4ce5f0d",
   "metadata": {},
   "source": [
    "## Exercise 3 - Working with Strings\n",
    "\n",
    "- Take the “lorem ipsum” String from down below and use it as a variable in Python\n",
    "- Complete the following tasks:\n",
    "  - How long is this text?\n",
    "  - How many words are in this text? (split and len)\n",
    "  - How often does each letter of the alphabet occur in this text? (re, len and a loop)\n",
    "  - Are the words “minim”, “anim”, “caesar”, “brutus” and “duis” in the string?\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur int occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "415d7232-241c-4ee8-8ff0-c48cea585d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "S = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6806f1fa-2f7a-41dc-b77b-ca1fda7d8930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has 445 characters.\n",
      "The text has 69 words.\n"
     ]
    }
   ],
   "source": [
    "#Finding the characters and words\n",
    "print(f\"The text has {len(S)} characters.\")\n",
    "print(f\"The text has {len(S.split())} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "325fa2d4-3f17-42c9-8926-42c6ccb961a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "a occurs 29 times.\n",
      "b occurs 3 times.\n",
      "c occurs 16 times.\n",
      "d occurs 18 times.\n",
      "e occurs 37 times.\n",
      "f occurs 3 times.\n",
      "g occurs 3 times.\n",
      "h occurs 1 times.\n",
      "i occurs 42 times.\n",
      "j occurs 0 times.\n",
      "k occurs 0 times.\n",
      "l occurs 21 times.\n",
      "m occurs 17 times.\n",
      "n occurs 24 times.\n",
      "o occurs 29 times.\n",
      "p occurs 11 times.\n",
      "q occurs 5 times.\n",
      "r occurs 22 times.\n",
      "s occurs 18 times.\n",
      "t occurs 32 times.\n",
      "u occurs 28 times.\n",
      "v occurs 3 times.\n",
      "w occurs 0 times.\n",
      "x occurs 3 times.\n",
      "y occurs 0 times.\n",
      "z occurs 0 times.\n",
      "A occurs 0 times.\n",
      "B occurs 0 times.\n",
      "C occurs 0 times.\n",
      "D occurs 1 times.\n",
      "E occurs 1 times.\n",
      "F occurs 0 times.\n",
      "G occurs 0 times.\n",
      "H occurs 0 times.\n",
      "I occurs 0 times.\n",
      "J occurs 0 times.\n",
      "K occurs 0 times.\n",
      "L occurs 1 times.\n",
      "M occurs 0 times.\n",
      "N occurs 0 times.\n",
      "O occurs 0 times.\n",
      "P occurs 0 times.\n",
      "Q occurs 0 times.\n",
      "R occurs 0 times.\n",
      "S occurs 0 times.\n",
      "T occurs 0 times.\n",
      "U occurs 1 times.\n",
      "V occurs 0 times.\n",
      "W occurs 0 times.\n",
      "X occurs 0 times.\n",
      "Y occurs 0 times.\n",
      "Z occurs 0 times.\n"
     ]
    }
   ],
   "source": [
    "#making a list of all letters of the alphabet\n",
    "all =  list(string.ascii_letters)\n",
    "print(all)\n",
    "\n",
    "#the long version\n",
    "for letr in all:\n",
    "    print(f\"{letr} occurs {len(re.findall(letr,S))} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fef5089-4c15-418c-aeb9-5b1a9f111a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A occurs 0 times and a occurs 29 times.\n",
      "A or a occur a total of 29 times.\n",
      "\n",
      "B occurs 0 times and b occurs 3 times.\n",
      "B or b occur a total of 3 times.\n",
      "\n",
      "C occurs 0 times and c occurs 16 times.\n",
      "C or c occur a total of 16 times.\n",
      "\n",
      "D occurs 1 times and d occurs 18 times.\n",
      "D or d occur a total of 19 times.\n",
      "\n",
      "E occurs 1 times and e occurs 37 times.\n",
      "E or e occur a total of 38 times.\n",
      "\n",
      "F occurs 0 times and f occurs 3 times.\n",
      "F or f occur a total of 3 times.\n",
      "\n",
      "G occurs 0 times and g occurs 3 times.\n",
      "G or g occur a total of 3 times.\n",
      "\n",
      "H occurs 0 times and h occurs 1 times.\n",
      "H or h occur a total of 1 times.\n",
      "\n",
      "I occurs 0 times and i occurs 42 times.\n",
      "I or i occur a total of 42 times.\n",
      "\n",
      "J occurs 0 times and j occurs 0 times.\n",
      "J or j occur a total of 0 times.\n",
      "\n",
      "K occurs 0 times and k occurs 0 times.\n",
      "K or k occur a total of 0 times.\n",
      "\n",
      "L occurs 1 times and l occurs 21 times.\n",
      "L or l occur a total of 22 times.\n",
      "\n",
      "M occurs 0 times and m occurs 17 times.\n",
      "M or m occur a total of 17 times.\n",
      "\n",
      "N occurs 0 times and n occurs 24 times.\n",
      "N or n occur a total of 24 times.\n",
      "\n",
      "O occurs 0 times and o occurs 29 times.\n",
      "O or o occur a total of 29 times.\n",
      "\n",
      "P occurs 0 times and p occurs 11 times.\n",
      "P or p occur a total of 11 times.\n",
      "\n",
      "Q occurs 0 times and q occurs 5 times.\n",
      "Q or q occur a total of 5 times.\n",
      "\n",
      "R occurs 0 times and r occurs 22 times.\n",
      "R or r occur a total of 22 times.\n",
      "\n",
      "S occurs 0 times and s occurs 18 times.\n",
      "S or s occur a total of 18 times.\n",
      "\n",
      "T occurs 0 times and t occurs 32 times.\n",
      "T or t occur a total of 32 times.\n",
      "\n",
      "U occurs 1 times and u occurs 28 times.\n",
      "U or u occur a total of 29 times.\n",
      "\n",
      "V occurs 0 times and v occurs 3 times.\n",
      "V or v occur a total of 3 times.\n",
      "\n",
      "W occurs 0 times and w occurs 0 times.\n",
      "W or w occur a total of 0 times.\n",
      "\n",
      "X occurs 0 times and x occurs 3 times.\n",
      "X or x occur a total of 3 times.\n",
      "\n",
      "Y occurs 0 times and y occurs 0 times.\n",
      "Y or y occur a total of 0 times.\n",
      "\n",
      "Z occurs 0 times and z occurs 0 times.\n",
      "Z or z occur a total of 0 times.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#making a list of all letters of the alphabet\n",
    "lower = list(string.ascii_lowercase)\n",
    "# print(lower)\n",
    "# Printing a list of uppercase alphabets.\n",
    "upper = list(string.ascii_uppercase)\n",
    "\n",
    "#the (slightly) more fancy version\n",
    "for LET,let in zip(upper,lower):\n",
    "    print(f\"{LET} occurs {len(re.findall(LET,S))} times and {let} occurs {len(re.findall(let,S))} times.\")\n",
    "    print(f\"{LET} or {let} occur a total of {len(re.findall(LET,S)) + len(re.findall(let,S))} times.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c2fdc69-e960-4b30-bc1b-fba0636adb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minim is part of the string.\n",
      "anim is part of the string.\n",
      "caesar is not part of the string.\n",
      "brutus is not part of the string.\n",
      "duis is not part of the string.\n"
     ]
    }
   ],
   "source": [
    "# Are the words “minim”, “anim”, “caesar”, “brutus” and “duis” in the string?\n",
    "list_words = [\"minim\",\"anim\",\"caesar\", \"brutus\",\"duis\"]\n",
    "\n",
    "for word in list_words:\n",
    "    if word in S:\n",
    "        print(f\"{word} is part of the string.\")\n",
    "    else:\n",
    "        print(f\"{word} is not part of the string.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3722e6ac-6e75-4103-a3bd-e8e3414020e9",
   "metadata": {},
   "source": [
    "## Exercise 4 - A bit more about Strings\n",
    "\n",
    "Take the “lorem ipsum” string from Exercise 03 and complete the following tasks:\n",
    "\n",
    "- Replace the strings et, in and eu with at, on and au\n",
    "- Create an all lower case and an all upper case variant of it\n",
    "- Split the text in it’s words and concatenate them together again (split and a loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75b466f5-3bc2-44e7-a5c9-f16f84ccbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Lorem = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3460e8b2-e81b-496a-b427-33e5a841acd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amat, consectatur adipiscong elit, sed do eiusmod tempor oncididunt ut labore at dolore magna aliqua. Ut enim ad monim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor on reprehenderit on voluptate velit esse cillum dolore au fugiat nulla pariatur. Exceptaur sont occaecat cupidatat non proident, sunt on culpa qui officia deserunt mollit anim id est laborum.\n"
     ]
    }
   ],
   "source": [
    "#Replace syllables\n",
    "Lorem_repl = Lorem.replace(\"et\",\"at\")\n",
    "Lorem_repl = Lorem_repl.replace(\"in\",\"on\")\n",
    "Lorem_repl = Lorem_repl.replace(\"eu\",\"au\")\n",
    "\n",
    "print(Lorem_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a421b44-152b-4332-90ac-c4d45fb30f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOREM IPSUM DOLOR SIT AMET, CONSECTETUR ADIPISCING ELIT, SED DO EIUSMOD TEMPOR INCIDIDUNT UT LABORE ET DOLORE MAGNA ALIQUA. UT ENIM AD MINIM VENIAM, QUIS NOSTRUD EXERCITATION ULLAMCO LABORIS NISI UT ALIQUIP EX EA COMMODO CONSEQUAT. DUIS AUTE IRURE DOLOR IN REPREHENDERIT IN VOLUPTATE VELIT ESSE CILLUM DOLORE EU FUGIAT NULLA PARIATUR. EXCEPTEUR SINT OCCAECAT CUPIDATAT NON PROIDENT, SUNT IN CULPA QUI OFFICIA DESERUNT MOLLIT ANIM ID EST LABORUM.\n",
      "\n",
      "lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"
     ]
    }
   ],
   "source": [
    "#Write text in all upper and all lower case\n",
    "Lorem_upper = Lorem.upper()\n",
    "Lorem_lower = Lorem.lower()\n",
    "\n",
    "print(Lorem_upper)\n",
    "print()\n",
    "print(Lorem_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b75b6526-3da2-4449-a23f-59efe61a5fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipiscing', 'elit', 'sed', 'do', 'eiusmod', 'tempor', 'incididunt', 'ut', 'labore', 'et', 'dolore', 'magna', 'aliqua', 'Ut', 'enim', 'ad', 'minim', 'veniam', 'quis', 'nostrud', 'exercitation', 'ullamco', 'laboris', 'nisi', 'ut', 'aliquip', 'ex', 'ea', 'commodo', 'consequat', 'Duis', 'aute', 'irure', 'dolor', 'in', 'reprehenderit', 'in', 'voluptate', 'velit', 'esse', 'cillum', 'dolore', 'eu', 'fugiat', 'nulla', 'pariatur', 'Excepteur', 'sint', 'occaecat', 'cupidatat', 'non', 'proident', 'sunt', 'in', 'culpa', 'qui', 'officia', 'deserunt', 'mollit', 'anim', 'id', 'est', 'laborum']\n",
      "\n",
      "LoremipsumdolorsitametconsecteturadipiscingelitseddoeiusmodtemporincididuntutlaboreetdoloremagnaaliquaUtenimadminimveniamquisnostrudexercitationullamcolaborisnisiutaliquipexeacommodoconsequatDuisauteiruredolorinreprehenderitinvoluptatevelitessecillumdoloreeufugiatnullapariaturExcepteursintoccaecatcupidatatnonproidentsuntinculpaquiofficiadeseruntmollitanimidestlaborum\n"
     ]
    }
   ],
   "source": [
    "# split the words\n",
    "Lorem_split = [elem for elem in re.split(\" |,|\\\\.\", Lorem) if len(elem)>0]\n",
    "print(Lorem_split)\n",
    "print()\n",
    "\n",
    "#concatenate the words\n",
    "Lorem_conc = \"\"\n",
    "for elem in Lorem_split: \n",
    "    Lorem_conc+=elem\n",
    "\n",
    "print(Lorem_conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff29a90c-f5b3-424e-b333-fe1fce050ad7",
   "metadata": {},
   "source": [
    "## Exercise 5 - Writing Files\n",
    "\n",
    "Write a program that creates two different files.\n",
    "\n",
    "- The first file should be opened normally and two lines should be written in it.\n",
    "- Afterwards close the file, open it again and add another three lines of text to the file (use the operator „a“ for append)\n",
    "- The second file should be generated by using„with“ and a loop to write a countdown from 10 to 0\n",
    "- Each number should be in a separate line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57f9738a-1a2c-43aa-98a3-f949535334ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the non-existing File Exercise5_File1.txt and add some lines, save by closing\n",
    "file1 = open(\"Exercise5_File1.txt\",\"w\")\n",
    "file1.write(\"Today is Wednesday, 10th of April 2024\\n\")\n",
    "file1.write(\"This is File 1 of Exercise 5 in Module 3.1 of my Bioinformatics Course\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54dc87b0-de11-4493-906c-b38fac3a4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some more line to the first file\n",
    "file1b = open(\"Exercise5_File1.txt\",\"a\")\n",
    "file1b.write(\"I have to add another couple of lines to this thing.\\n\")\n",
    "file1b.write(\"Today the sun is shining. It is colder than it was on the weekend but still nice.\\n\")\n",
    "file1b.write(\"I just ate a piece of bread with Momo's fabulous abricot jam :-)\\n\")\n",
    "file1b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfa02f38-4884-4ca5-a422-86996f2d3f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'10\\n9\\n8\\n7\\n6\\n5\\n4\\n3\\n2\\n1\\n0\\n'\n"
     ]
    }
   ],
   "source": [
    "# create a string with the countdown\n",
    "exc5_2 = \"\"\n",
    "for i in range(10,-1,-1):\n",
    "    exc5_2 += str(i) + \"\\n\"\n",
    "\n",
    "print(repr(exc5_2))\n",
    "\n",
    "# write the countdown into a new file using with\n",
    "with open(\"Exercise5_File2.txt\", \"w\") as with_file:\n",
    "    with_file.write(exc5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccc79fd8-19cc-4df6-9efd-2fbcbddf22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing a bit shorter:\n",
    "with open(\"Exercise5_File2.txt\", \"w\") as with_file:\n",
    "    for i in range(0,11):\n",
    "        with_file.write(str(i)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb757f6c-87a4-4c94-bd5f-403011f2801d",
   "metadata": {},
   "source": [
    "## Exercise 6 - Reading a file\n",
    "\n",
    "- Read in your second file from exercise 5, the one with the countdown, by using the last method we discussed, the one using a for loop inside the with statement\n",
    "- Calculate the sum of the numbers and print out the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1cad2470-24bf-4b01-87c7-8052ffdd5f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.0\n"
     ]
    }
   ],
   "source": [
    "with open(\"Exercise5_File2.txt\",\"r\") as read_file:\n",
    "    result = 0\n",
    "    for line in read_file:\n",
    "        result += float(line)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "915bd1c3-6a1b-4950-a236-39b720edd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I make a more complex example, where there is a string at the end \n",
    "# so I can't just sum up the numbers\n",
    "\n",
    "with open(\"Exercise5_File3.txt\",\"w\") as file:\n",
    "    for i in range(0,1500,200):\n",
    "        file.write(str(i)+\" x\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e54f677e-7512-41eb-8f60-9387d033449f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "\n",
      "5600\n"
     ]
    }
   ],
   "source": [
    "# since I have numbers ranging from 1 digit to 4 digits \n",
    "# I can't just take the slice from the start\n",
    "# Since I always have the same from the end though (\\n,x and space)\n",
    "# I can access my number irrespective of length from the back\n",
    "with open(\"Exercise5_File3.txt\",\"r\") as read_file:\n",
    "    result2 = 0\n",
    "    for line in read_file:\n",
    "        print(line[:-3])\n",
    "        result2 += int(line[:-2])\n",
    "\n",
    "print()\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c751799-f007-43ff-867b-0fe99934e5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "\n",
      "5600\n"
     ]
    }
   ],
   "source": [
    "# now how would I do if there were variable text afterwards?\n",
    "# since the number is always the first element followed by a space I can simply split the lines\n",
    "# and use the first element\n",
    "with open(\"Exercise5_File3.txt\",\"r\") as read_file:\n",
    "    result2 = 0\n",
    "    for line in read_file:\n",
    "        print(line.split()[0])\n",
    "        result2 += int(line.split()[0])\n",
    "\n",
    "print()\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd531f-9cc4-4f20-9ec3-ce9d32709b41",
   "metadata": {},
   "source": [
    "## Exercise 7 - Small sequence comparison\n",
    "\n",
    "- You have four fasta files called XP_021046627, XP_031236805, A0A8I4A5I4 and ELR51227\n",
    "- Write a program that reads in all four of them\n",
    "- Afterwards compare the first three sequences letter by letter with each other (use a simple loop) and calculate how many identical letters these sequences have\n",
    "- Compare the fourth sequence with the remaining three in a similar matter, be careful this sequence is 3 amino acids longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8dc03cc5-ccc1-402b-9875-2c52356a41fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNGTEGPNFYVPFSNVTGVVRSPFEQPQYYLAEPWQFSMLAAYMFLLIVLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCDLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVVFTWIMALACAAPPLVGWSRYIPEGMQCSCGIDYYTLKPEVNNESFVIYMFVVHFTIPMTVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVVIMVIFFLICWLPYAGVAFYIFTHQGSNFGPIFMTLPAFFAKSSSIYNPVIYIMLNKQFRNCMLTTLCCGKNPLGDDDASATASKTETSQVAPA\n"
     ]
    }
   ],
   "source": [
    "#XP_021046627, XP_031236805, A0A8I4A5I4 and ELR51227\n",
    "#reading in the files\n",
    "import fastaparser\n",
    "\n",
    "with open(\"XP_021046627.fasta\",\"r\") as fasta_file:\n",
    "    fasta1 = fastaparser.Reader(fasta_file)\n",
    "    for seq in fasta1:\n",
    "        print(seq.sequence_as_string())\n",
    "        seq1 = seq.sequence_as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c03c5ca-0cd2-4a99-8a2c-aca461d162e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNGTEGPNFYVPFSNITGVVRSPFEQPQYYLAEPWQFSMLAAYMFLLIVLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTLKPEVNNESFVIYMFVVHFTIPMIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIFFLICWLPYASVAMYIFTHQGSNFGPIFMTLPAFFAKSSSIYNPVIYIMLNKQFRNCMLTTLCCGKNPLGDDDASATASKTETSQVAPA\n"
     ]
    }
   ],
   "source": [
    "with open(\"XP_031236805.fasta\",\"r\") as fasta_file:\n",
    "    fasta2 = fastaparser.Reader(fasta_file)\n",
    "    for seq in fasta2:\n",
    "        print(seq.sequence_as_string())\n",
    "        seq2 = seq.sequence_as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f42a36fd-9ffe-4bbf-a4d7-3ba3b7c73b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNGTEGPNFYVPFSNATGVVRSPFEYPQYYLAEPWQFSMLAAYMFLLIVLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFIFGPTGCNAEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLAGWSRYIPEGLQCSCGIDYYTLKPEVNNESFVIYMFVVHFTIPMIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWVPYASVAFYIFTHQGSNFGPIFMTIPAFFAKSAAIYNPVIYIMMNKQFRNCMLTTICCGKNPLGDDEASATVSKTETSQVAPA\n"
     ]
    }
   ],
   "source": [
    "with open(\"A0A8I4A5I4.fasta\",\"r\") as fasta_file:\n",
    "    fasta3 = fastaparser.Reader(fasta_file)\n",
    "    for seq in fasta3:\n",
    "        print(seq.sequence_as_string())\n",
    "        seq3 = seq.sequence_as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cbb8fc5f-f291-40b0-9de6-1388863560e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMLLLIVLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\n"
     ]
    }
   ],
   "source": [
    "with open(\"ELR51227.fasta\",\"r\") as fasta_file:\n",
    "    fasta4 = fastaparser.Reader(fasta_file)\n",
    "    for seq in fasta4:\n",
    "        print(seq.sequence_as_string())\n",
    "        seq4 = seq.sequence_as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95a98fa5-bf06-44de-ae29-9fba42c9bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 348 348\n"
     ]
    }
   ],
   "source": [
    "# comparing the first three sequences\n",
    "# They all have the same length\n",
    "print(len(seq1), len(seq2), len(seq3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47c410d4-fafc-4705-be60-d0eb9d5a0653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1, 2 and 3 have a total of 326 amino acids in common\n",
      "Sequence 1 and 2 have a total of 340 amino acids in common\n",
      "Sequence 1 and 3 have a total of 327 amino acids in common\n",
      "Sequence 2 and 3 have a total of 332 amino acids in common\n"
     ]
    }
   ],
   "source": [
    "#counting how many aa are the same in the same position\n",
    "count_all = 0\n",
    "count_12 = 0\n",
    "count_13 = 0\n",
    "count_23 = 0\n",
    "for i in range(len(seq1)):\n",
    "    if seq1[i] == seq2[i]:\n",
    "        count_12+=1\n",
    "    if seq1[i] == seq3[i]:\n",
    "        count_13+=1\n",
    "    if seq2[i] == seq3[i]:\n",
    "        count_23+=1\n",
    "    if seq1[i] == seq2[i] == seq3[i]:\n",
    "        count_all+=1\n",
    "\n",
    "print(f\"Sequence 1, 2 and 3 have a total of {count_all} amino acids in common\")\n",
    "print(f\"Sequence 1 and 2 have a total of {count_12} amino acids in common\")\n",
    "print(f\"Sequence 1 and 3 have a total of {count_13} amino acids in common\")\n",
    "print(f\"Sequence 2 and 3 have a total of {count_23} amino acids in common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4773c3f3-2ecf-4214-b20e-95428c1bbef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'count_all2': 16, 'count_14': 16, 'count_24': 17, 'count_34': 18}, 1: {'count_all2': 21, 'count_14': 22, 'count_24': 22, 'count_34': 21}, 2: {'count_all2': 34, 'count_14': 38, 'count_24': 36, 'count_34': 35}, 3: {'count_all2': 314, 'count_14': 323, 'count_24': 326, 'count_34': 326}}\n",
      "\n",
      "For an Alignment Shift of 0 in Seq4, it has 16 AA in common with Seq1.\n",
      "For an Alignment Shift of 0 in Seq4, it has 17 AA in common with Seq2.\n",
      "For an Alignment Shift of 0 in Seq4, it has 18 AA in common with Seq3.\n",
      "For an Alignment Shift of 0 in Seq4, the four sequences have 16 AA in common.\n",
      "\n",
      "For an Alignment Shift of 1 in Seq4, it has 22 AA in common with Seq1.\n",
      "For an Alignment Shift of 1 in Seq4, it has 22 AA in common with Seq2.\n",
      "For an Alignment Shift of 1 in Seq4, it has 21 AA in common with Seq3.\n",
      "For an Alignment Shift of 1 in Seq4, the four sequences have 21 AA in common.\n",
      "\n",
      "For an Alignment Shift of 2 in Seq4, it has 38 AA in common with Seq1.\n",
      "For an Alignment Shift of 2 in Seq4, it has 36 AA in common with Seq2.\n",
      "For an Alignment Shift of 2 in Seq4, it has 35 AA in common with Seq3.\n",
      "For an Alignment Shift of 2 in Seq4, the four sequences have 34 AA in common.\n",
      "\n",
      "For an Alignment Shift of 3 in Seq4, it has 323 AA in common with Seq1.\n",
      "For an Alignment Shift of 3 in Seq4, it has 326 AA in common with Seq2.\n",
      "For an Alignment Shift of 3 in Seq4, it has 326 AA in common with Seq3.\n",
      "For an Alignment Shift of 3 in Seq4, the four sequences have 314 AA in common.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#comparing to seq4, taking into consideration that the three extra amino acids could be in the beginning or the end!\n",
    "count_all2 = 0\n",
    "count_14 = 0\n",
    "count_24 = 0\n",
    "count_34 = 0\n",
    "\n",
    "shift_counts = {}\n",
    "\n",
    "for j in range (4):\n",
    "    shift_counts[j] = {}\n",
    "    shift_counts[j][\"count_all2\"] = 0\n",
    "    shift_counts[j][\"count_14\"] = 0\n",
    "    shift_counts[j][\"count_24\"] = 0\n",
    "    shift_counts[j][\"count_34\"] = 0\n",
    "    for i in range(len(seq1)):\n",
    "        if seq1[i] == seq4[i+j]:\n",
    "            shift_counts[j][\"count_14\"]+=1\n",
    "        if seq2[i] == seq4[i+j]:\n",
    "            shift_counts[j][\"count_24\"]+=1\n",
    "        if seq3[i] == seq4[i+j]:\n",
    "            shift_counts[j][\"count_34\"]+=1\n",
    "        if seq1[i] == seq2[i] == seq3[i] == seq4[i+j]:\n",
    "            shift_counts[j][\"count_all2\"]+=1\n",
    "\n",
    "print(shift_counts)\n",
    "print()\n",
    "            \n",
    "for key in shift_counts:\n",
    "    print(f\"For an Alignment Shift of {key} in Seq4, it has {shift_counts[key][\"count_14\"]} AA in common with Seq1.\")\n",
    "    print(f\"For an Alignment Shift of {key} in Seq4, it has {shift_counts[key][\"count_24\"]} AA in common with Seq2.\")\n",
    "    print(f\"For an Alignment Shift of {key} in Seq4, it has {shift_counts[key][\"count_34\"]} AA in common with Seq3.\")\n",
    "    print(f\"For an Alignment Shift of {key} in Seq4, the four sequences have {shift_counts[key][\"count_all2\"]} AA in common.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bc760-113d-4b1c-8fc7-5343f184a34a",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671662e8-a9c4-46c1-b641-adf7b2cdbd0c",
   "metadata": {},
   "source": [
    "## Accessing the letters of the alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eae273ee-3ec4-45f4-b160-dd54e69f8ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "# Python program to print a list of alphabets.\n",
    "# Importing the string module.\n",
    "import string\n",
    "# Printing a list of lowercase alphabets.\n",
    "lower = list(string.ascii_lowercase)\n",
    "print(lower)\n",
    "# Printing a list of uppercase alphabets.\n",
    "upper = list(string.ascii_uppercase)\n",
    "print(upper)\n",
    "# Printing a list of lower and uppercase alphabet\n",
    "all = list(string.ascii_letters)\n",
    "print(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cb62f-0789-451c-aef4-4c368e052dcc",
   "metadata": {},
   "source": [
    "## whitespaces with escape characters\n",
    "\n",
    "|Symbol|Meaning|\n",
    "|--|--|\n",
    "|`\\n`|Linebreak|\n",
    "|`\\t`|tabstop|\n",
    "|`\\s`|any white space (including space and tab)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3343c-080a-4433-aa59-503a7bd76b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
